{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column | Description\n",
    ":---|:---\n",
    "`area` | Area of the real estate (in m-square)\n",
    "`bathrooms` | Number of bathrooms\n",
    "`bedrooms` | Number of rooms\n",
    "`condo_fee`| Montly maintenance fee (in USD)\n",
    "`parking_spots`| Number of parking spots\n",
    "`price`| Price of the real estate (in USD)\n",
    "`suites` | Number of bedrooms with direct access to bathroom.\n",
    "`type` | Kind of real estate\n",
    "`lat` | Latitude of the property\n",
    "`lon` | Longitude of the property\n",
    "`misc` | Other information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much information is given about the data itself. The best way to describe your data is looking directly at it.\n",
    "\n",
    "> ### Task 1:\n",
    "Use `pandas` do explore the data:\n",
    "- **Take an overall look at the tabular data.**\n",
    "- **Check the data shape.**\n",
    "- **Check the types of values in each column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is already loaded below\n",
    "data = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another crucial step during data analysis is to identify and clean possible problems in the dataset. Some of the problems that could be present in a dataset are *Missing Values*, *Duplicates* and *Inconsistency*.In real world dataset is quite messy and we need to clean it before we do some analysis on it.\n",
    "\n",
    "> ### Task 2:\n",
    "Using `pandas`, clean the data making sure that you address these problems:\n",
    "- **Missing values**\n",
    "    Remove all those columns where more than 95% of values are missing.Also drop rows where more than 2 values are missing if they constitute **less than 3% of total sample size.**\n",
    "- **Duplicates**\n",
    "    Drop duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Descriptive Statistics\n",
    "\n",
    "A simple and fast way to better understand the data is to calculate descriptive statistics about it. They provide a a better notion of variables range and distribution. Additionally, they can show the presence of impossible values in the dataset. Removing these values is crucial to a good performance of the created model later.\n",
    "In this case, a possible inconsistency could be present in the columns `parking_spots` or `bedrooms`. They should be positive.\n",
    "\n",
    "**OBS.: Do not confuse inconsistent values with outliers. In general, outliers are unlikely but plausible data entries. While inconsistent entries are impossible, e. g. negative area.**\n",
    "\n",
    "> ### Task 3:\n",
    "Explore the statistics behind the data with  `pandas`:\n",
    "- **Calculate descriptive statistics of numeric and categorical columns.**\n",
    "- **Remove inconsistent entries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is the most frequent <b>type</b> of real estate? <br>\n",
    "Q2. What is the <b>median</b> number of <b>bedrooms</b>?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:<br>\n",
    "1.<br>\n",
    "2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Visualization\n",
    "\n",
    "Visualization is the best way better understand the data.\n",
    "\n",
    "> #### Task 4:\n",
    "Using any plotting library (`matplotlib`, `seaborn`, `folium`, etc..), select an appropriate graphs for each step:\n",
    "- **Plot the approximate distributions of numeric and categorical variables.**\n",
    "- **Create relevant plot to easily represent the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Outliers\n",
    "\n",
    "From the information acquired from the previous plots and statistics, we can remove outliers in columns with long-tailed distributions. Ideally, we should investigate these **outliers**, check where came from, if they are valid data points, or if they come from mistyping, etc. \n",
    "\n",
    "> #### Task 5:\n",
    "Perform these steps in the data:\n",
    "- **Deal with the outliers in the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Correlations\n",
    "\n",
    "Now, let's verify correlations of the features in the data. In general, good numeric features have a high absolute value of [**Pearson Correlation**](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) with the target variable, and low value with other relevant features.\n",
    "\n",
    "> #### Task 6:\n",
    "Explore the correlations between the features in the dataset:\n",
    "- **Calculate the correlation between numeric feature.**\n",
    "- **Choose appropriate visualizations to display these correlations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n",
    "\n",
    "Now, it is time to prepare the features for the model. Multiple times, combining some features could be interesting for the model performance. Additionally, some features should be treated to better represent their meaning. \n",
    "\n",
    "> #### Task 7:\n",
    "Perform what is asked below:\n",
    "- **Transform the coordinate features in a more appropriate representation.**\n",
    "- **Feel free to combine any other features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint:\n",
    "\n",
    "For example, `lat` and `lon` features represent angles on a sphere which is not a good metric to our problem. A possible approach is to first convert the `lat` and `lon` coordinates in their normalized cartesian coordinates using the formulas below:\n",
    "\n",
    "$$ x = \\cos{(lat)} \\cdot \\cos{(lon)} $$\n",
    "$$ y = \\cos{(lat)} \\cdot \\sin{(lon)} $$\n",
    "$$ z = \\sin{(lat)} $$\n",
    "\n",
    "After that, create a cluster model to classify each entry based on its closest neighbors. In general, [Elbow method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)) is a good technique to choose the adequate number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Prepare Features for Model\n",
    "\n",
    "In general, some steps must to be performed before feeding the data to the model. This step depends on the model selected, but using a simple linear model is always a good a ideal.\n",
    "\n",
    "> #### Task 8:\n",
    "Considering a linear model, prepare all the numeric and categorical features following these steps: \n",
    "- **Perform adequade transformations to numeric features.**\n",
    "- **Perform adequade transformations to categorical features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Model Training and Evaluation\n",
    "\n",
    "Finally, the data is prepared to be feed to the model. In regression problem, linear models are good candidates because they are easily explainable and not computationally intensive.\n",
    "\n",
    "> #### Task 9:\n",
    "Using models from `sklearn.linear_model`, perform these tasks:\n",
    "- **Create a linear model and fit it to the data.**\n",
    "- **Calculate the expected *RMSE*, *MAE* and *R2* scores of the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
